{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "import dbfread\n",
    "from dbfread import DBF\n",
    "import dbf\n",
    "from glob import glob \n",
    "\n",
    "import pandas as pd\n",
    "import csv\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc, font_manager\n",
    "import matplotlib.font_manager as fm\n",
    "from matplotlib import font_manager, rc\n",
    "rc('font', family='AppleGothic')\n",
    "import plotly as py\n",
    "import plotly.express as px\n",
    "from plotly import graph_objs as go\n",
    "from plotly.subplots import make_subplots\n",
    "import seaborn as sns\n",
    "\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import datetime\n",
    "\n",
    "import pickle\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, LeaveOneGroupOut, StratifiedKFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../dataset')\n",
    "dir_data = os.getcwd()\n",
    "filename = 'lab_DATASET_v16.pickle'\n",
    "audio_filename = 'lab_DATASET_audio_new_v1.pickle'\n",
    "\n",
    "with open(os.path.join(dir_data, filename), 'rb') as f:\n",
    "  DATASET = pickle.load(f)\n",
    "with open(os.path.join(dir_data, audio_filename), 'rb') as f:\n",
    "  audio_DATASET = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pnum = [1,2,3,4,8,10,12,13,14,16,18,19,20,21,22,23,25,26,27] # 5: 임산부 / 6: voice없음 / 7: 라벨없음 / 9: 웃기다고함 / 11,17: E4이상 / 24: 임산부 / 15: 높은 PSS 점수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/iclab/yunjo-server/KEmoWork/modeling/model_utils.py:54: FutureWarning: DataFrame.interpolate with method=pad is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  result = result.interpolate(method='pad')\n",
      "/home/iclab/yunjo-server/KEmoWork/modeling/model_utils.py:54: FutureWarning: DataFrame.interpolate with method=pad is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  result = result.interpolate(method='pad')\n",
      "/home/iclab/yunjo-server/KEmoWork/modeling/model_utils.py:54: FutureWarning: DataFrame.interpolate with method=pad is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  result = result.interpolate(method='pad')\n",
      "/home/iclab/yunjo-server/KEmoWork/modeling/model_utils.py:54: FutureWarning: DataFrame.interpolate with method=pad is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  result = result.interpolate(method='pad')\n",
      "/home/iclab/yunjo-server/KEmoWork/modeling/model_utils.py:54: FutureWarning: DataFrame.interpolate with method=pad is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  result = result.interpolate(method='pad')\n",
      "/home/iclab/yunjo-server/KEmoWork/modeling/model_utils.py:54: FutureWarning: DataFrame.interpolate with method=pad is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  result = result.interpolate(method='pad')\n",
      "/home/iclab/yunjo-server/KEmoWork/modeling/model_utils.py:54: FutureWarning: DataFrame.interpolate with method=pad is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  result = result.interpolate(method='pad')\n",
      "/home/iclab/yunjo-server/KEmoWork/modeling/model_utils.py:54: FutureWarning: DataFrame.interpolate with method=pad is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  result = result.interpolate(method='pad')\n",
      "/home/iclab/yunjo-server/KEmoWork/modeling/model_utils.py:54: FutureWarning: DataFrame.interpolate with method=pad is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  result = result.interpolate(method='pad')\n",
      "/home/iclab/yunjo-server/KEmoWork/modeling/model_utils.py:54: FutureWarning: DataFrame.interpolate with method=pad is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  result = result.interpolate(method='pad')\n",
      "/home/iclab/yunjo-server/KEmoWork/modeling/model_utils.py:54: FutureWarning: DataFrame.interpolate with method=pad is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  result = result.interpolate(method='pad')\n",
      "/home/iclab/yunjo-server/KEmoWork/modeling/model_utils.py:54: FutureWarning: DataFrame.interpolate with method=pad is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  result = result.interpolate(method='pad')\n",
      "/home/iclab/yunjo-server/KEmoWork/modeling/model_utils.py:54: FutureWarning: DataFrame.interpolate with method=pad is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  result = result.interpolate(method='pad')\n",
      "/home/iclab/yunjo-server/KEmoWork/modeling/model_utils.py:54: FutureWarning: DataFrame.interpolate with method=pad is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  result = result.interpolate(method='pad')\n",
      "/home/iclab/yunjo-server/KEmoWork/modeling/model_utils.py:54: FutureWarning: DataFrame.interpolate with method=pad is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  result = result.interpolate(method='pad')\n",
      "/home/iclab/yunjo-server/KEmoWork/modeling/model_utils.py:54: FutureWarning: DataFrame.interpolate with method=pad is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  result = result.interpolate(method='pad')\n",
      "/home/iclab/yunjo-server/KEmoWork/modeling/model_utils.py:54: FutureWarning: DataFrame.interpolate with method=pad is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  result = result.interpolate(method='pad')\n",
      "/home/iclab/yunjo-server/KEmoWork/modeling/model_utils.py:54: FutureWarning: DataFrame.interpolate with method=pad is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  result = result.interpolate(method='pad')\n",
      "/home/iclab/yunjo-server/KEmoWork/modeling/model_utils.py:54: FutureWarning: DataFrame.interpolate with method=pad is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  result = result.interpolate(method='pad')\n"
     ]
    }
   ],
   "source": [
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "import model_utils\n",
    "from model_utils import signal_interp\n",
    "\n",
    "EDA = pd.DataFrame()\n",
    "EEG = pd.DataFrame()\n",
    "TEMP = pd.DataFrame()\n",
    "ACC = pd.DataFrame()\n",
    "ECG = pd.DataFrame()\n",
    "\n",
    "STRESS = pd.DataFrame()\n",
    "AROUSAL = pd.DataFrame()\n",
    "VALENCE = pd.DataFrame()\n",
    "\n",
    "for p in pnum:\n",
    "    eda_data = DATASET[str(p)]['data']['e4_eda']\n",
    "    eeg_data = DATASET[str(p)]['data']['muse']\n",
    "    temp_data = DATASET[str(p)]['data']['e4_temp']\n",
    "    acc_data = DATASET[str(p)]['data']['e4_acc']\n",
    "    bvp_data = DATASET[str(p)]['data']['e4_bvp']\n",
    "    ecg_data = DATASET[str(p)]['data']['polar_ecg']\n",
    "\n",
    "    stress_data = DATASET[str(p)]['labels']['stress']\n",
    "    arousal_data = DATASET[str(p)]['labels']['arousal']\n",
    "    valence_data = DATASET[str(p)]['labels']['valence']\n",
    "    \n",
    "    eeg_data = signal_interp(eeg_data, 256)\n",
    "\n",
    "    t_eda = eda_data['Timestamp'].tolist()\n",
    "    t_eeg = eeg_data['Timestamp'].tolist()\n",
    "    t_temp = temp_data['Timestamp'].tolist()\n",
    "    t_acc = acc_data['Timestamp'].tolist()\n",
    "    t_bvp = bvp_data['Timestamp'].tolist()\n",
    "    t_ecg = ecg_data['Timestamp'].tolist()\n",
    "    t_stress = stress_data['Timestamp'].tolist()\n",
    "    t_arousal = arousal_data['Timestamp'].tolist()\n",
    "    t_valence = valence_data['Timestamp'].tolist()\n",
    "\n",
    "    max_start = max(t_eda[0], t_eeg[0], t_temp[0], t_acc[0], t_bvp[0], t_ecg[0], t_stress[0], t_arousal[0], t_valence[0])\n",
    "    min_end = min(t_eda[-1], t_eeg[-1], t_temp[-1], t_acc[-1], t_bvp[-1], t_ecg[-1], t_stress[-1], t_arousal[-1], t_valence[-1])\n",
    "    \n",
    "    eda_data = eda_data.loc[(eda_data['Timestamp']>=max_start) & (eda_data['Timestamp']<=min_end)]\n",
    "    eeg_data = eeg_data.loc[(eeg_data['Timestamp']>=max_start) & (eeg_data['Timestamp']<=min_end)] \n",
    "    temp_data = temp_data.loc[(temp_data['Timestamp']>=max_start) & (temp_data['Timestamp']<=min_end)]\n",
    "    acc_data = acc_data.loc[(acc_data['Timestamp']>=max_start) & (acc_data['Timestamp']<=min_end)]\n",
    "    bvp_data = bvp_data.loc[(bvp_data['Timestamp']>=max_start) & (bvp_data['Timestamp']<=min_end)]\n",
    "    ecg_data = ecg_data.loc[(ecg_data['Timestamp']>=max_start) & (ecg_data['Timestamp']<=min_end)]\n",
    "    stress_data = stress_data.loc[(stress_data['Timestamp']>=max_start) & (stress_data['Timestamp']<=min_end)]        \n",
    "    arousal_data = arousal_data.loc[(arousal_data['Timestamp']>=max_start) & (arousal_data['Timestamp']<=min_end)]        \n",
    "    valence_data = valence_data.loc[(valence_data['Timestamp']>=max_start) & (valence_data['Timestamp']<=min_end)]\n",
    "\n",
    "    marker = DATASET[str(p)]['data']['marker']\n",
    "    c1_s = marker['Timestamp'][marker['session']=='c1_start']\n",
    "    c1_e = marker['Timestamp'][marker['session']=='c1_end']\n",
    "    c2_s = marker['Timestamp'][marker['session']=='c2_start']\n",
    "    c2_e = marker['Timestamp'][marker['session']=='c2_end']\n",
    "    c3_s = marker['Timestamp'][marker['session']=='c3_start']\n",
    "    c3_e = marker['Timestamp'][marker['session']=='c3_end']\n",
    "\n",
    "    eda_data = pd.concat([eda_data.loc[(eda_data['Timestamp']>=c1_s.values[0]) & (eda_data['Timestamp']<=c1_e.values[0])],\n",
    "                          eda_data.loc[(eda_data['Timestamp']>=c2_s.values[0]) & (eda_data['Timestamp']<=c2_e.values[0])],\n",
    "                          eda_data.loc[(eda_data['Timestamp']>=c3_s.values[0]) & (eda_data['Timestamp']<=c3_e.values[0])]], axis=0, ignore_index=True)\n",
    "    eeg_data = pd.concat([eeg_data.loc[(eeg_data['Timestamp']>=c1_s.values[0]) & (eeg_data['Timestamp']<=c1_e.values[0])],\n",
    "                          eeg_data.loc[(eeg_data['Timestamp']>=c2_s.values[0]) & (eeg_data['Timestamp']<=c2_e.values[0])],\n",
    "                          eeg_data.loc[(eeg_data['Timestamp']>=c3_s.values[0]) & (eeg_data['Timestamp']<=c3_e.values[0])]], axis=0, ignore_index=True)\n",
    "    temp_data = pd.concat([temp_data.loc[(temp_data['Timestamp']>=c1_s.values[0]) & (temp_data['Timestamp']<=c1_e.values[0])],\n",
    "                          temp_data.loc[(temp_data['Timestamp']>=c2_s.values[0]) & (temp_data['Timestamp']<=c2_e.values[0])],\n",
    "                          temp_data.loc[(temp_data['Timestamp']>=c3_s.values[0]) & (temp_data['Timestamp']<=c3_e.values[0])]], axis=0, ignore_index=True)\n",
    "    acc_data = pd.concat([acc_data.loc[(acc_data['Timestamp']>=c1_s.values[0]) & (acc_data['Timestamp']<=c1_e.values[0])],\n",
    "                          acc_data.loc[(acc_data['Timestamp']>=c2_s.values[0]) & (acc_data['Timestamp']<=c2_e.values[0])],\n",
    "                          acc_data.loc[(acc_data['Timestamp']>=c3_s.values[0]) & (acc_data['Timestamp']<=c3_e.values[0])]], axis=0, ignore_index=True)\n",
    "    bvp_data = pd.concat([bvp_data.loc[(bvp_data['Timestamp']>=c1_s.values[0]) & (bvp_data['Timestamp']<=c1_e.values[0])],\n",
    "                          bvp_data.loc[(bvp_data['Timestamp']>=c2_s.values[0]) & (bvp_data['Timestamp']<=c2_e.values[0])],\n",
    "                          bvp_data.loc[(bvp_data['Timestamp']>=c3_s.values[0]) & (bvp_data['Timestamp']<=c3_e.values[0])]], axis=0, ignore_index=True)\n",
    "    ecg_data = pd.concat([ecg_data.loc[(ecg_data['Timestamp']>=c1_s.values[0]) & (ecg_data['Timestamp']<=c1_e.values[0])],\n",
    "                          ecg_data.loc[(ecg_data['Timestamp']>=c2_s.values[0]) & (ecg_data['Timestamp']<=c2_e.values[0])],\n",
    "                          ecg_data.loc[(ecg_data['Timestamp']>=c3_s.values[0]) & (ecg_data['Timestamp']<=c3_e.values[0])]], axis=0, ignore_index=True)\n",
    "    \n",
    "    len_1 = len(stress_data.loc[(stress_data['Timestamp']>=c1_s.values[0]) & (stress_data['Timestamp']<=c1_e.values[0])])\n",
    "    len_2 = len(stress_data.loc[(stress_data['Timestamp']>=c2_s.values[0]) & (stress_data['Timestamp']<=c2_e.values[0])])\n",
    "    len_3 = len(stress_data.loc[(stress_data['Timestamp']>=c3_s.values[0]) & (stress_data['Timestamp']<=c3_e.values[0])])\n",
    "    \n",
    "    arr_1 = np.zeros(len_1)\n",
    "    arr_2 = np.ones(len_2)\n",
    "    arr_3 = np.ones(len_3)\n",
    "\n",
    "    arr_label = np.concatenate((arr_1, arr_2, arr_3))\n",
    "    \n",
    "    dict_data = {'signal':\n",
    "            {'EDA': eda_data[[' eda']].to_numpy(),\n",
    "            'EEG': eeg_data[['TP9', 'AF7', 'AF8', 'TP10']].to_numpy(),\n",
    "            'TEMP': temp_data[[' temp']].to_numpy(),\n",
    "            'ACC': acc_data[[' accX', ' accY', ' accZ']].to_numpy(),\n",
    "            'BVP': bvp_data[[' bvp']].to_numpy(),\n",
    "            'ECG': ecg_data[['ecg [uV]']].to_numpy()},\n",
    "                'label':\n",
    "            {'STRESS': arr_label},\n",
    "                'subject': f\"S{p}\"}\n",
    "    \n",
    "    # os.chdir('../dataset/KEmoWork/')\n",
    "\n",
    "    folder_name = f\"S{p}\"\n",
    "    if not os.path.exists(folder_name):\n",
    "        os.makedirs(folder_name)\n",
    "    \n",
    "    pkl_file_path = os.path.join(folder_name, f\"S{p}.pkl\")\n",
    "    with open(pkl_file_path, 'wb') as pkl_file:\n",
    "        pickle.dump(dict_data, pkl_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iitp-emotion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "48b21541b7c2dfb74d8092eff7e025277566ca5fc697397747fe365767b645a3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
