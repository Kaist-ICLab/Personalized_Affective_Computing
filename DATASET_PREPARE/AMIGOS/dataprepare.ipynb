{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import scipy\n",
    "from pathlib import Path\n",
    "\n",
    "def load_mat_file(participant_id, base_path):\n",
    "    \"\"\"Load .mat file and return the data.\"\"\"\n",
    "    filename = f'Data_Original_P{participant_id:02d}.mat'\n",
    "    filepath = os.path.join(base_path, f'Data_Original_P{participant_id:02d}', filename)\n",
    "    return scipy.io.loadmat(filepath)\n",
    "\n",
    "selfreports = pd.read_excel(\"SelfAsessment.xlsx\")\n",
    "averages = selfreports.groupby('pnum').agg({'arousal': 'mean', 'valence': 'mean'}).reset_index()\n",
    "averages = averages.rename(columns={'arousal': 'avg_arousal', 'valence': 'avg_valence'})\n",
    "selfreports = selfreports.merge(averages, on='pnum')\n",
    "selfreports['ars'] = (selfreports['arousal'] > selfreports['avg_arousal']).astype(int)\n",
    "selfreports['vls'] = (selfreports['valence'] > selfreports['avg_valence']).astype(int)\n",
    "\n",
    "\n",
    "def save_participant_data(participant_id, base_path):\n",
    "    #print(\"pnum: \", participant_id)\n",
    "    mat_file = load_mat_file(participant_id, base_path)\n",
    "\n",
    "    # Process each modality data\n",
    "    mod_data = mat_file['EEG_DATA']\n",
    "    eeg_data = mod_data[0][0:16]\n",
    "    eeg_data_list = []\n",
    "\n",
    "    for i in range(16):\n",
    "        temp = pd.DataFrame(eeg_data[i][:, 3:17])\n",
    "        temp['ars'] = selfreports.loc[(selfreports['pnum']==participant_id) & (selfreports['vnum']==i+1), 'arousal'].values[0]\n",
    "        temp['vlc'] = selfreports.loc[(selfreports['pnum']==participant_id) & (selfreports['vnum']==i+1), 'valence'].values[0]\n",
    "        eeg_data_list.append(temp)\n",
    "\n",
    "    eeg_data_list = pd.concat(eeg_data_list, axis=0, ignore_index=True)\n",
    "    #print(eeg_data_list.shape)\n",
    "\n",
    "    mod_data = mat_file['ECG_DATA']\n",
    "    ecg_data = mod_data[0][0:16]\n",
    "    ecg_data_list = []\n",
    "\n",
    "    for i in range(16):\n",
    "        ecg_data_list.append(pd.DataFrame(ecg_data[i][:, 1:3]))\n",
    "\n",
    "    ecg_data_list = pd.concat(ecg_data_list, axis=0, ignore_index=True)\n",
    "    #print(ecg_data_list.shape)\n",
    "\n",
    "    mod_data = mat_file['GSR_DATA']\n",
    "    gsr_data = mod_data[0][0:16]\n",
    "    gsr_data_list = []\n",
    "\n",
    "    for i in range(16):\n",
    "        gsr_data_list.append(pd.DataFrame(gsr_data[i][:, 1:5]))\n",
    "\n",
    "    gsr_data_list = pd.concat(gsr_data_list, axis=0, ignore_index=True)\n",
    "    #print(gsr_data_list.shape)\n",
    "\n",
    "\n",
    "    # Prepare dictionary for pickle file\n",
    "    dict_data = {\n",
    "        'signal': {\n",
    "            'eeg': eeg_data_list.iloc[:, :14].to_numpy(),\n",
    "            'ecg': ecg_data_list.iloc[:, :].to_numpy(),\n",
    "            'gsr': gsr_data_list.iloc[:, :].to_numpy()\n",
    "        },\n",
    "        'label': {\n",
    "            'AROUSAL': eeg_data_list['ars'].to_numpy(),\n",
    "            'VALENCE': eeg_data_list['vlc'].to_numpy(),\n",
    "        },\n",
    "        'subject': f\"S{participant_id}\"\n",
    "    }\n",
    "    \n",
    "    # Create folder if it doesn't exist\n",
    "    folder_name = f\"S{participant_id}\"\n",
    "    Path(folder_name).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Save dictionary as pickle file\n",
    "    with open(Path(folder_name) / f\"S{participant_id}.pkl\", 'wb') as pkl_file:\n",
    "        pickle.dump(dict_data, pkl_file)\n",
    "    \n",
    "participant_ids = [1,2,3,4,5,6,7,8,10,11,13,14,15,16,17,18,19,20,25,26,27,28,29,30,31,32,34,35,36,37,38,39,40]    \n",
    "\n",
    "def process_all_participants(base_path):\n",
    "    for participant_id in participant_ids:\n",
    "        save_participant_data(participant_id, base_path)\n",
    "\n",
    "# Set the base path where your zip files are stored\n",
    "base_path = './'\n",
    "process_all_participants(base_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import zipfile\n",
    "# import pandas as pd\n",
    "# import pickle\n",
    "# import scipy\n",
    "# from pathlib import Path\n",
    "\n",
    "# def load_mat_file(participant_id, base_path):\n",
    "#     \"\"\"Load .mat file and return the data.\"\"\"\n",
    "#     filename = f'Data_Original_P{participant_id:02d}.mat'\n",
    "#     filepath = os.path.join(base_path, f'Data_Original_P{participant_id:02d}', filename)\n",
    "#     return scipy.io.loadmat(filepath)\n",
    "\n",
    "# selfreports = pd.read_excel(\"SelfAsessment.xlsx\")\n",
    "# averages = selfreports.groupby('pnum').agg({'arousal': 'mean', 'valence': 'mean'}).reset_index()\n",
    "# averages = averages.rename(columns={'arousal': 'avg_arousal', 'valence': 'avg_valence'})\n",
    "# selfreports = selfreports.merge(averages, on='pnum')\n",
    "# selfreports['ars'] = (selfreports['arousal'] > selfreports['avg_arousal']).astype(int)\n",
    "# selfreports['vls'] = (selfreports['valence'] > selfreports['avg_valence']).astype(int)\n",
    "\n",
    "\n",
    "# def save_participant_data(participant_id, base_path):\n",
    "#     #print(\"pnum: \", participant_id)\n",
    "#     mat_file = load_mat_file(participant_id, base_path)\n",
    "\n",
    "#     # Process each modality data\n",
    "#     mod_data = mat_file['EEG_DATA']\n",
    "#     eeg_data = mod_data[0][0:16]\n",
    "#     eeg_data_list = []\n",
    "\n",
    "#     for i in range(16):\n",
    "#         temp = pd.DataFrame(eeg_data[i][:, 3:17])\n",
    "#         temp['ars'] = selfreports.loc[(selfreports['pnum']==participant_id) & (selfreports['vnum']==i+1), 'ars'].values[0]\n",
    "#         temp['vlc'] = selfreports.loc[(selfreports['pnum']==participant_id) & (selfreports['vnum']==i+1), 'vls'].values[0]\n",
    "#         eeg_data_list.append(temp)\n",
    "\n",
    "#     eeg_data_list = pd.concat(eeg_data_list, axis=0, ignore_index=True)\n",
    "#     #print(eeg_data_list.shape)\n",
    "\n",
    "#     mod_data = mat_file['ECG_DATA']\n",
    "#     ecg_data = mod_data[0][0:16]\n",
    "#     ecg_data_list = []\n",
    "\n",
    "#     for i in range(16):\n",
    "#         ecg_data_list.append(pd.DataFrame(ecg_data[i][:, 1:3]))\n",
    "\n",
    "#     ecg_data_list = pd.concat(ecg_data_list, axis=0, ignore_index=True)\n",
    "#     #print(ecg_data_list.shape)\n",
    "\n",
    "#     mod_data = mat_file['GSR_DATA']\n",
    "#     gsr_data = mod_data[0][0:16]\n",
    "#     gsr_data_list = []\n",
    "\n",
    "#     for i in range(16):\n",
    "#         gsr_data_list.append(pd.DataFrame(gsr_data[i][:, 1:5]))\n",
    "\n",
    "#     gsr_data_list = pd.concat(gsr_data_list, axis=0, ignore_index=True)\n",
    "#     #print(gsr_data_list.shape)\n",
    "\n",
    "\n",
    "#     # Prepare dictionary for pickle file\n",
    "#     dict_data = {\n",
    "#         'signal': {\n",
    "#             'eeg': eeg_data_list.iloc[:, :14].to_numpy(),\n",
    "#             'ecg': ecg_data_list.iloc[:, :].to_numpy(),\n",
    "#             'gsr': gsr_data_list.iloc[:, :].to_numpy()\n",
    "#         },\n",
    "#         'label': {\n",
    "#             'AROUSAL': eeg_data_list['ars'].to_numpy(),\n",
    "#             'VALENCE': eeg_data_list['vlc'].to_numpy(),\n",
    "#         },\n",
    "#         'subject': f\"S{participant_id}\"\n",
    "#     }\n",
    "    \n",
    "#     # Create folder if it doesn't exist\n",
    "#     folder_name = f\"S{participant_id}\"\n",
    "#     Path(folder_name).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "#     # Save dictionary as pickle file\n",
    "#     with open(Path(folder_name) / f\"S{participant_id}.pkl\", 'wb') as pkl_file:\n",
    "#         pickle.dump(dict_data, pkl_file)\n",
    "    \n",
    "# participant_ids = [1,2,3,4,5,6,7,8,10,11,13,14,15,16,17,18,19,20,25,26,27,28,29,30,31,32,34,35,36,37,38,39,40]    \n",
    "\n",
    "# def process_all_participants(base_path):\n",
    "#     for participant_id in participant_ids:\n",
    "#         save_participant_data(participant_id, base_path)\n",
    "\n",
    "# # Set the base path where your zip files are stored\n",
    "# base_path = './'\n",
    "# process_all_participants(base_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selfreports.loc[(selfreports['pnum']==1) & (selfreports['vnum']==1), 'ars'].values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OLD ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/path/to/data/Movie_P01/ECG_Clip01.mat'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/miniforge3/envs/pers_ac/lib/python3.11/site-packages/scipy/io/matlab/_mio.py:39\u001b[0m, in \u001b[0;36m_open_file\u001b[0;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 39\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(file_like, mode), \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;66;03m# Probably \"not found\"\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/path/to/data/Movie_P01/ECG_Clip01.mat'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[75], line 74\u001b[0m\n\u001b[1;32m     71\u001b[0m base_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/path/to/data\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m subject_id \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m59\u001b[39m):\n\u001b[0;32m---> 74\u001b[0m     \u001b[43mpreprocess_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubject_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbase_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[75], line 55\u001b[0m, in \u001b[0;36mpreprocess_data\u001b[0;34m(subject_id, base_path)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpreprocess_data\u001b[39m(subject_id, base_path):\n\u001b[1;32m     54\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Preprocess ECG and GSR data for a subject and save it.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 55\u001b[0m     ecg_data \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocess_ecg_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubject_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbase_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m     eeg_data \u001b[38;5;241m=\u001b[39m preprocess_eeg_data(subject_id, base_path)\n\u001b[1;32m     57\u001b[0m     gsr_data \u001b[38;5;241m=\u001b[39m preprocess_gsr_data(subject_id, base_path)\n",
      "Cell \u001b[0;32mIn[75], line 16\u001b[0m, in \u001b[0;36mpreprocess_ecg_data\u001b[0;34m(subject_id, base_path)\u001b[0m\n\u001b[1;32m     14\u001b[0m all_ecg_data \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m filepath \u001b[38;5;129;01min\u001b[39;00m ecg_file_paths:\n\u001b[0;32m---> 16\u001b[0m     mat_data \u001b[38;5;241m=\u001b[39m \u001b[43mload_mat_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m     data_ecg \u001b[38;5;241m=\u001b[39m mat_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData_ECG\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     18\u001b[0m     timestamp \u001b[38;5;241m=\u001b[39m data_ecg[:, \u001b[38;5;241m0\u001b[39m]\n",
      "Cell \u001b[0;32mIn[75], line 7\u001b[0m, in \u001b[0;36mload_mat_file\u001b[0;34m(filepath)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_mat_file\u001b[39m(filepath):\n\u001b[1;32m      6\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load .mat file and return the data.\"\"\"\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mscipy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloadmat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/pers_ac/lib/python3.11/site-packages/scipy/io/matlab/_mio.py:225\u001b[0m, in \u001b[0;36mloadmat\u001b[0;34m(file_name, mdict, appendmat, **kwargs)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;124;03mLoad MATLAB file.\u001b[39;00m\n\u001b[1;32m     90\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;124;03m    3.14159265+3.14159265j])\u001b[39;00m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    224\u001b[0m variable_names \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvariable_names\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 225\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_open_file_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mappendmat\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[43m    \u001b[49m\u001b[43mMR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmat_reader_factory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    227\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmatfile_dict\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mMR\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_variables\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvariable_names\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/pers_ac/lib/python3.11/contextlib.py:137\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgen)\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerator didn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt yield\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/pers_ac/lib/python3.11/site-packages/scipy/io/matlab/_mio.py:17\u001b[0m, in \u001b[0;36m_open_file_context\u001b[0;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;129m@contextmanager\u001b[39m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_context\u001b[39m(file_like, appendmat, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m---> 17\u001b[0m     f, opened \u001b[38;5;241m=\u001b[39m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_like\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mappendmat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     19\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m f\n",
      "File \u001b[0;32m~/miniforge3/envs/pers_ac/lib/python3.11/site-packages/scipy/io/matlab/_mio.py:45\u001b[0m, in \u001b[0;36m_open_file\u001b[0;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m appendmat \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m file_like\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.mat\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m     44\u001b[0m         file_like \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.mat\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 45\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(file_like, mode), \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\n\u001b[1;32m     48\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mReader needs file name or open file-like object\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     49\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/path/to/data/Movie_P01/ECG_Clip01.mat'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "\n",
    "def load_mat_file(filepath):\n",
    "    \"\"\"Load .mat file and return the data.\"\"\"\n",
    "    return scipy.io.loadmat(filepath)\n",
    "\n",
    "def preprocess_ecg_data(subject_id, base_path):\n",
    "    \"\"\"Preprocess ECG data for a subject.\"\"\"\n",
    "    ecg_file_template = \"ECG_Clip{:02d}.mat\"\n",
    "    ecg_file_paths = [os.path.join(base_path, f\"Movie_P{subject_id:02d}\", ecg_file_template.format(i)) for i in range(1, 37)]\n",
    "\n",
    "    all_ecg_data = []\n",
    "    for filepath in ecg_file_paths:\n",
    "        mat_data = load_mat_file(filepath)\n",
    "        data_ecg = mat_data[\"Data_ECG\"]\n",
    "        timestamp = data_ecg[:, 0]\n",
    "        #acc_data = data_ecg[:, 1:4] if data_ecg.shape[1] > 3 else None\n",
    "        ecg_data = data_ecg[:, -1:-2]\n",
    "\n",
    "        ecg_data = {\n",
    "            \"timestamp\": timestamp,\n",
    "            #\"acc_data\": acc_data,\n",
    "            \"ecg\": ecg_data,\n",
    "        }\n",
    "        all_ecg_data.append(ecg_data)\n",
    "    \n",
    "    return all_ecg_data\n",
    "\n",
    "def preprocess_gsr_data(subject_id, base_path):\n",
    "    \"\"\"Preprocess GSR data for a subject.\"\"\"\n",
    "    gsr_file_template = \"GSR_Clip{:02d}.mat\"\n",
    "    gsr_file_paths = [os.path.join(base_path, f\"Movie_P{subject_id:02d}\", gsr_file_template.format(i)) for i in range(1, 37)]\n",
    "\n",
    "    all_gsr_data = []\n",
    "    for filepath in gsr_file_paths:\n",
    "        mat_data = load_mat_file(filepath)\n",
    "        data_gsr = mat_data[\"Data_GSR\"]\n",
    "        timestamp = data_gsr[:, 0]\n",
    "        acc_data = data_gsr[:, 1:4]\n",
    "        eda_data = data_gsr[:, -1]\n",
    "\n",
    "        gsr_data = {\n",
    "            \"timestamp\": timestamp,\n",
    "            \"acc_data\": acc_data,\n",
    "            \"eda_data\": eda_data\n",
    "        }\n",
    "        all_gsr_data.append(gsr_data)\n",
    "    \n",
    "    return all_gsr_data\n",
    "\n",
    "def preprocess_data(subject_id, base_path):\n",
    "    \"\"\"Preprocess ECG and GSR data for a subject and save it.\"\"\"\n",
    "    ecg_data = preprocess_ecg_data(subject_id, base_path)\n",
    "    eeg_data = preprocess_eeg_data(subject_id, base_path)\n",
    "    gsr_data = preprocess_gsr_data(subject_id, base_path)\n",
    "\n",
    "    data = {\n",
    "        \"ecg\": ecg_data,\n",
    "        \"gsr\": gsr_data\n",
    "    }\n",
    "\n",
    "    save_path = os.path.join(base_path, f\"S{subject_id:02d}\", f\"S{subject_id:02d}.pkl\")\n",
    "    os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "\n",
    "    with open(save_path, 'wb') as f:\n",
    "        pickle.dump(data, f)\n",
    "\n",
    "# Example usage for all subjects\n",
    "base_path = \"/path/to/data\"\n",
    "\n",
    "for subject_id in range(1, 59):\n",
    "    preprocess_data(subject_id, base_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "\n",
    "def load_mat_file(filepath):\n",
    "    \"\"\"Load .mat file and return the data.\"\"\"\n",
    "    return scipy.io.loadmat(filepath)\n",
    "\n",
    "def preprocess_ecg_data(subject_id, base_path):\n",
    "    \"\"\"Preprocess ECG data for a subject.\"\"\"\n",
    "    ecg_file_template = \"ECG_Clip{:02d}.mat\"\n",
    "    ecg_file_paths = [os.path.join(base_path, f\"Movie_P{subject_id:02d}\", ecg_file_template.format(i)) for i in range(1, 37)]\n",
    "\n",
    "    all_ecg_data = []\n",
    "    for filepath in ecg_file_paths:\n",
    "        mat_data = load_mat_file(filepath)\n",
    "        data_ecg = mat_data[\"Data_ECG\"]\n",
    "        timestamp = data_ecg[:, 0]\n",
    "        #acc_data = data_ecg[:, 1:4] if data_ecg.shape[1] > 3 else None\n",
    "        ecg_data = data_ecg[:, -1:-2]\n",
    "\n",
    "        ecg_data = {\n",
    "            \"timestamp\": timestamp,\n",
    "            #\"acc_data\": acc_data,\n",
    "            \"ecg\": ecg_data,\n",
    "        }\n",
    "        all_ecg_data.append(ecg_data)\n",
    "    \n",
    "    return all_ecg_data\n",
    "\n",
    "def preprocess_gsr_data(subject_id, base_path):\n",
    "    \"\"\"Preprocess GSR data for a subject.\"\"\"\n",
    "    gsr_file_template = \"GSR_Clip{:02d}.mat\"\n",
    "    gsr_file_paths = [os.path.join(base_path, f\"Movie_P{subject_id:02d}\", gsr_file_template.format(i)) for i in range(1, 37)]\n",
    "\n",
    "    all_gsr_data = []\n",
    "    for filepath in gsr_file_paths:\n",
    "        mat_data = load_mat_file(filepath)\n",
    "        data_gsr = mat_data[\"Data_GSR\"]\n",
    "        timestamp = data_gsr[:, 0]\n",
    "        acc_data = data_gsr[:, 1:4]\n",
    "        eda_data = data_gsr[:, -1]\n",
    "\n",
    "        gsr_data = {\n",
    "            \"timestamp\": timestamp,\n",
    "            \"acc_data\": acc_data,\n",
    "            \"eda_data\": eda_data\n",
    "        }\n",
    "        all_gsr_data.append(gsr_data)\n",
    "    \n",
    "    return all_gsr_data\n",
    "\n",
    "def preprocess_data(subject_id, base_path):\n",
    "    \"\"\"Preprocess ECG and GSR data for a subject and save it.\"\"\"\n",
    "    ecg_data = preprocess_ecg_data(subject_id, base_path)\n",
    "    gsr_data = preprocess_gsr_data(subject_id, base_path)\n",
    "\n",
    "    data = {\n",
    "        \"ecg\": ecg_data,\n",
    "        \"gsr\": gsr_data\n",
    "    }\n",
    "\n",
    "    save_path = os.path.join(base_path, f\"S{subject_id:02d}\", f\"S{subject_id:02d}.pkl\")\n",
    "    os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "\n",
    "    with open(save_path, 'wb') as f:\n",
    "        pickle.dump(data, f)\n",
    "\n",
    "# Example usage for all subjects\n",
    "base_path = \"/path/to/data\"\n",
    "\n",
    "for subject_id in range(1, 59):\n",
    "    preprocess_data(subject_id, base_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import scipy.io\n",
    "# import numpy as np\n",
    "# import pickle\n",
    "# import pandas as pd\n",
    "\n",
    "# selfreports = scipy.io.loadmat('Dt_Selfreports.mat')\n",
    "# order_movie = scipy.io.loadmat('Dt_Order_Movie.mat')\n",
    "\n",
    "# ratings = selfreports['Ratings']\n",
    "\n",
    "# NS, NV = 58, 36\n",
    "\n",
    "# rating_comparison = {rating_type: [] for rating_type in ['Arousal', 'Valence']}\n",
    "\n",
    "# for rating_type_index, rating_type in enumerate(rating_comparison.keys()):\n",
    "#     rating_matrix = ratings[rating_type_index, :, :]  # NS x NV matrix for the current rating type\n",
    "#     average_ratings = rating_matrix.mean(axis=1)  # Calculate the average rating for each subject\n",
    "\n",
    "#     comparison_matrix = (rating_matrix > average_ratings[:, None]).astype(int)  # NS x NV boolean matrix\n",
    "#     rating_comparison[rating_type] = comparison_matrix\n",
    "\n",
    "# comparison_dfs = {rating_type: pd.DataFrame(data=comparison_matrix, columns=[f'Video_{i+1}' for i in range(NV)])\n",
    "#                   for rating_type, comparison_matrix in rating_comparison.items()}\n",
    "\n",
    "# def load_mat_file(filepath):\n",
    "#     \"\"\"Load .mat file and return the data.\"\"\"\n",
    "#     return scipy.io.loadmat(filepath)\n",
    "    \n",
    "# def preprocess_data(subject_id, base_path):\n",
    "#     ecg_file_template = \"ECG_Clip{}.mat\"\n",
    "#     ecg_file_paths = [os.path.join(base_path, f\"ECGData/Movie_P{subject_id:02d}\", ecg_file_template.format(i)) for i in range(1, 37)]\n",
    "\n",
    "#     all_ecg_data = pd.DataFrame()\n",
    "\n",
    "#     for idx, filepath in enumerate(ecg_file_paths):\n",
    "#         mat_data = load_mat_file(filepath)\n",
    "#         data_ecg = pd.DataFrame(mat_data[\"Data_ECG\"])\n",
    "#         ecg_data = data_ecg.iloc[:, -2:]\n",
    "        \n",
    "#         ars = comparison_dfs['Arousal'].iloc[subject_id-1][idx]\n",
    "#         vlc = comparison_dfs['Valence'].iloc[subject_id-1][idx]\n",
    "\n",
    "#         ecg_data['ars'] = ars\n",
    "#         ecg_data['vlc'] = vlc\n",
    "\n",
    "#         all_ecg_data = pd.concat([all_ecg_data, ecg_data], axis=0)\n",
    "\n",
    "#     print(all_ecg_data)\n",
    "\n",
    "#     gsr_file_template = \"GSR_Clip{}.mat\"\n",
    "#     gsr_file_paths = [os.path.join(base_path, f\"GSRData/Movie_P{subject_id:02d}\", gsr_file_template.format(i)) for i in range(1, 37)]\n",
    "\n",
    "#     all_gsr_data = pd.DataFrame()\n",
    "\n",
    "#     for filepath in gsr_file_paths:\n",
    "#         mat_data = load_mat_file(filepath)\n",
    "#         data_gsr = pd.DataFrame(mat_data[\"Data_GSR\"])\n",
    "#         acc_eda_data = data_gsr.iloc[:, 1:]\n",
    "\n",
    "#         all_gsr_data = pd.concat([all_gsr_data, acc_eda_data], axis=0)\n",
    "\n",
    "#     dict_data = {'signal':\n",
    "#             {'ecg': all_ecg_data.iloc[:,:1].to_numpy(),\n",
    "#             'acc': all_gsr_data.iloc[:,:2].to_numpy(),\n",
    "#             'eda': all_gsr_data.iloc[:,-1].to_numpy()},\n",
    "#             'label':\n",
    "#             {'AROUSAL': all_ecg_data[['ars']].to_numpy(),\n",
    "#             'VALENCE': all_ecg_data[['vlc']].to_numpy()},\n",
    "#             'subject': f\"S{subject_id}\"}\n",
    "\n",
    "#     folder_name = f\"S{subject_id}\"\n",
    "#     if not os.path.exists(folder_name):\n",
    "#         os.makedirs(folder_name)\n",
    "\n",
    "#     pkl_file_path = os.path.join(folder_name, f\"S{subject_id}.pkl\")\n",
    "#     with open(pkl_file_path, 'wb') as pkl_file:\n",
    "#         pickle.dump(dict_data, pkl_file)\n",
    "\n",
    "# base_path = \"./\"\n",
    "\n",
    "# for subject_id in range(1, 37):\n",
    "#     preprocess_data(subject_id, base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Dt_Selfreports.mat'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/miniforge3/envs/pers_ac/lib/python3.11/site-packages/scipy/io/matlab/_mio.py:39\u001b[0m, in \u001b[0;36m_open_file\u001b[0;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 39\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(file_like, mode), \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;66;03m# Probably \"not found\"\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Dt_Selfreports.mat'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[58], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Load the .mat files\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m selfreports \u001b[38;5;241m=\u001b[39m \u001b[43mscipy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloadmat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDt_Selfreports.mat\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m order_movie \u001b[38;5;241m=\u001b[39m scipy\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mloadmat(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDt_Order_Movie.mat\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Extract the ratings and the permutation list\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/pers_ac/lib/python3.11/site-packages/scipy/io/matlab/_mio.py:225\u001b[0m, in \u001b[0;36mloadmat\u001b[0;34m(file_name, mdict, appendmat, **kwargs)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;124;03mLoad MATLAB file.\u001b[39;00m\n\u001b[1;32m     90\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;124;03m    3.14159265+3.14159265j])\u001b[39;00m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    224\u001b[0m variable_names \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvariable_names\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 225\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_open_file_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mappendmat\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[43m    \u001b[49m\u001b[43mMR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmat_reader_factory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    227\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmatfile_dict\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mMR\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_variables\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvariable_names\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/pers_ac/lib/python3.11/contextlib.py:137\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgen)\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerator didn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt yield\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/pers_ac/lib/python3.11/site-packages/scipy/io/matlab/_mio.py:17\u001b[0m, in \u001b[0;36m_open_file_context\u001b[0;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;129m@contextmanager\u001b[39m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_context\u001b[39m(file_like, appendmat, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m---> 17\u001b[0m     f, opened \u001b[38;5;241m=\u001b[39m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_like\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mappendmat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     19\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m f\n",
      "File \u001b[0;32m~/miniforge3/envs/pers_ac/lib/python3.11/site-packages/scipy/io/matlab/_mio.py:45\u001b[0m, in \u001b[0;36m_open_file\u001b[0;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m appendmat \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m file_like\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.mat\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m     44\u001b[0m         file_like \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.mat\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 45\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(file_like, mode), \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\n\u001b[1;32m     48\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mReader needs file name or open file-like object\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     49\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Dt_Selfreports.mat'"
     ]
    }
   ],
   "source": [
    "import scipy.io\n",
    "import pandas as pd\n",
    "\n",
    "# Load the .mat files\n",
    "selfreports = scipy.io.loadmat('Dt_Selfreports.mat')\n",
    "order_movie = scipy.io.loadmat('Dt_Order_Movie.mat')\n",
    "\n",
    "# Extract the ratings and the permutation list\n",
    "ratings = selfreports['Ratings']\n",
    "print(ratings.shape)\n",
    "permutation_list = order_movie['PermutationList']\n",
    "\n",
    "# Number of subjects and videos (assuming NS and NV are the dimensions of the matrices)\n",
    "NS, NV = permutation_list.shape\n",
    "print(NV)\n",
    "\n",
    "# Initialize a dictionary to store whether each rating is higher or lower than the average\n",
    "rating_comparison = {rating_type: [] for rating_type in ['Arousal', 'Valence']}\n",
    "\n",
    "# Iterate over each rating type (0 to 4 in the 5 rating types)\n",
    "for rating_type_index, rating_type in enumerate(rating_comparison.keys()):\n",
    "    #rating_matrix = ratings[:, :, rating_type_index]  # NS x NV matrix for the current rating type\n",
    "    rating_matrix = ratings[rating_type_index, :, :]  # NS x NV matrix for the current rating type\n",
    "    average_ratings = rating_matrix.mean(axis=1)  # Calculate the average rating for each subject\n",
    "    print(average_ratings.shape)\n",
    "    \n",
    "    # Compare each rating with the subject's average rating\n",
    "    comparison_matrix = (rating_matrix > average_ratings[:, None]).astype(int)  # NS x NV boolean matrix\n",
    "    rating_comparison[rating_type] = comparison_matrix\n",
    "\n",
    "# Convert the results to DataFrames for easier manipulation if needed\n",
    "comparison_dfs = {rating_type: pd.DataFrame(data=comparison_matrix, columns=[f'Video_{i+1}' for i in range(NV)])\n",
    "                  for rating_type, comparison_matrix in rating_comparison.items()}\n",
    "\n",
    "# Print the comparison results for each rating type\n",
    "for rating_type, df in comparison_dfs.items():\n",
    "    print(f'Comparison for {rating_type}:')\n",
    "    print(df)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "import scipy.io\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "# Load ratings data\n",
    "selfreports = scipy.io.loadmat('Dt_Selfreports.mat')\n",
    "ratings = selfreports['Ratings']\n",
    "\n",
    "NS, NV = 58, 36\n",
    "\n",
    "# Compute average ratings for each subject and comparison matrices\n",
    "rating_comparison = {}\n",
    "for rating_type in ['Arousal', 'Valence']:\n",
    "    rating_matrix = ratings[['Arousal', 'Valence'].index(rating_type), :, :]\n",
    "    average_ratings = rating_matrix.mean(axis=1)\n",
    "    comparison_matrix = (rating_matrix > average_ratings[:, None]).astype(int)\n",
    "    rating_comparison[rating_type] = pd.DataFrame(comparison_matrix, columns=[f'Video_{i+1}' for i in range(NV)])\n",
    "\n",
    "def load_mat_file(filepath):\n",
    "    \"\"\"Load .mat file and return the data.\"\"\"\n",
    "    return scipy.io.loadmat(filepath)\n",
    "\n",
    "def preprocess_data(subject_id, base_path):\n",
    "    # Initialize empty lists to store data\n",
    "    all_ecg_data = []\n",
    "    all_gsr_data = []\n",
    "    \n",
    "    # Process ECG data\n",
    "    for idx in range(1, 37):\n",
    "        ecg_filepath = Path(base_path) / f\"ECGData/Movie_P{subject_id:02d}/ECG_Clip{idx}.mat\"\n",
    "        mat_data = load_mat_file(ecg_filepath)\n",
    "        data_ecg = pd.DataFrame(mat_data[\"Data_ECG\"])\n",
    "        ecg_data = data_ecg.iloc[:, -2:]\n",
    "        \n",
    "        # Assign ars and vlc values\n",
    "        ecg_data['ars'] = rating_comparison['Arousal'].iloc[subject_id - 1, idx - 1]\n",
    "        ecg_data['vlc'] = rating_comparison['Valence'].iloc[subject_id - 1, idx - 1]\n",
    "        \n",
    "        all_ecg_data.append(ecg_data)\n",
    "    \n",
    "    # Concatenate all_ecg_data into a single DataFrame\n",
    "    all_ecg_data = pd.concat(all_ecg_data, axis=0, ignore_index=True)\n",
    "    \n",
    "    # Process GSR data\n",
    "    for idx in range(1, 37):\n",
    "        gsr_filepath = Path(base_path) / f\"GSRData/Movie_P{subject_id:02d}/GSR_Clip{idx}.mat\"\n",
    "        mat_data = load_mat_file(gsr_filepath)\n",
    "        data_gsr = pd.DataFrame(mat_data[\"Data_GSR\"])\n",
    "        acc_eda_data = data_gsr.iloc[:, 1:]\n",
    "        \n",
    "        all_gsr_data.append(acc_eda_data)\n",
    "    \n",
    "    # Concatenate all_gsr_data into a single DataFrame\n",
    "    all_gsr_data = pd.concat(all_gsr_data, axis=0, ignore_index=True)\n",
    "    \n",
    "    # Prepare dictionary for pickle file\n",
    "    dict_data = {\n",
    "        'signal': {\n",
    "            'ecg': all_ecg_data.iloc[:, :2].to_numpy(),\n",
    "            'acc': all_gsr_data.iloc[:, :3].to_numpy(),\n",
    "            'eda': all_gsr_data.iloc[:, -1].to_numpy(),\n",
    "        },\n",
    "        'label': {\n",
    "            'AROUSAL': all_ecg_data['ars'].to_numpy(),\n",
    "            'VALENCE': all_ecg_data['vlc'].to_numpy(),\n",
    "        },\n",
    "        'subject': f\"S{subject_id}\"\n",
    "    }\n",
    "    \n",
    "    # Create folder if it doesn't exist\n",
    "    folder_name = f\"S{subject_id}\"\n",
    "    Path(folder_name).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Save dictionary as pickle file\n",
    "    with open(Path(folder_name) / f\"S{subject_id}.pkl\", 'wb') as pkl_file:\n",
    "        pickle.dump(dict_data, pkl_file)\n",
    "\n",
    "# Base path\n",
    "base_path = \"./\"\n",
    "\n",
    "# Process data for each subject\n",
    "for subject_id in range(1, 2):\n",
    "    preprocess_data(subject_id, base_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pers_ac",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
